{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inferencia\n",
        "Para realizar inferencia con los modelos obtenidos, debemos contar con un estado inicial, que en este caso podría representar el inicio de la noticia que queremos crear. De esta manera, usamos el modelo para que nos de el próximo caracter o palabra de la noticia iterando sobre el resultado hasta que se logre la logitud deseada"
      ],
      "metadata": {
        "id": "MFlFtHtQGPTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "gDmOmmGLGRW9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab de caracteres\n",
        "vocab = [' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '\\\\', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
      ],
      "metadata": {
        "id": "dQQjvSINGiEG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para modelo a nivel de caracter\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "vocab_size\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "NXevTe_EGtKX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = self.embedding(inputs, training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x\n",
        "    def load_model(self, filepath):\n",
        "      return tf.keras.models.load_weights(filepath)"
      ],
      "metadata": {
        "id": "7cDXGHeDHPFi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "9DLGSKq2HRfh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llamar al método build() del modelo con las dimensiones de entrada\n",
        "model.build(tf.TensorShape([None, None]))\n",
        "\n",
        "# Ahora puedes llamar a model.summary()\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67oTiyGkHUa7",
        "outputId": "d7898b58-11c5-4161-ea24-c8477a170941"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  21248     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  85075     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4044627 (15.43 MB)\n",
            "Trainable params: 4044627 (15.43 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1xeRI1UE0ZZIrmrxgs9x_U3p7bSmSSpF1?usp=sharing\", quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sU65nOjIi1D",
        "outputId": "2cc0b0c5-1f9f-4237-e090-49b3208a3e47"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/AA2-Models_and_vocab/character-article-model.data-00000-of-00001',\n",
              " '/content/AA2-Models_and_vocab/character-article-model.index',\n",
              " '/content/AA2-Models_and_vocab/vocab.txt',\n",
              " '/content/AA2-Models_and_vocab/word-article-model.data-00000-of-00001',\n",
              " '/content/AA2-Models_and_vocab/word-article-model.index']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('AA2-Models_and_vocab/character-article-model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKqqY7DVInMt",
        "outputId": "47d2621f-28b4-4dc4-fb78-fa59658e0743"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a6f02884dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_body = 'News announced that new hedge funds could go  '\n",
        "seq_length=100\n",
        "for i in range(200):\n",
        "  inputs = [ids_from_chars(tf.strings.unicode_split(current_body, 'UTF-8'))]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=seq_length, padding='pre')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  predictions = model(inputs)\n",
        "  predictions = predictions[-1, :]\n",
        "  predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "  current_body += ids_from_chars.get_vocabulary()[predicted_id]\n",
        "  if ids_from_chars.get_vocabulary()[predicted_id] == '\\n':\n",
        "    break\n",
        "print(current_body)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSLaO1MjIu78",
        "outputId": "a90fa2c9-045e-4bbc-e30f-0abc0a21d9b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News announced that new hedge funds could go  a place to lift three games -- whose growing part a suicide car bomber in Buidlin's focused Taiwan's governing update to Mac OS initial future USL preparations were ushering its new iPod math between \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La inferencia del modelo a caracteres parece tener sentido a lo sumo viendo n-gramas. Sin embargo pierde contexto a largo plazo facilmente y parece alucinar. De todas maneras, cada palabra parece tener sentido por lo menos con las contiguas."
      ],
      "metadata": {
        "id": "js-P4NXLPUkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferencia palabra a palabra"
      ],
      "metadata": {
        "id": "azoPndTGP0Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar la lista desde un archivo de texto\n",
        "with open('AA2-Models_and_vocab/vocab.txt', 'r') as f:\n",
        "    vocab = [line.strip() for line in f]\n",
        "\n",
        "print(\"Vocabulario cargado desde 'vocab.txt'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVkvme5vK1Kl",
        "outputId": "a7eb24b2-7c94-4a54-f310-8195b00bf4e4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario cargado desde 'vocab.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para modelo a nivel de caracter\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "vocab_size\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 512"
      ],
      "metadata": {
        "id": "a5Jk1GP9PxAx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "# Llamar al método build() del modelo con las dimensiones de entrada\n",
        "model.build(tf.TensorShape([None, None]))\n",
        "\n",
        "# Ahora puedes llamar a model.summary()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbhbDBZvP32I",
        "outputId": "c878cf41-2ac7-4385-b212-c7038e76eadf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     multiple                  1920256   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 multiple                  1182720   \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  3848013   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6950989 (26.52 MB)\n",
            "Trainable params: 6950989 (26.52 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('AA2-Models_and_vocab/word-article-model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBhzh1hUP87j",
        "outputId": "c35c8853-efd1-4790-f3e3-f6982322020d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a6f05fa26e0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "current_body = 'New beauty product just launched in '\n",
        "for i in range(20):\n",
        "  # Convert to lowercase\n",
        "  article = current_body.lower()\n",
        "  # Remove special characters, keeping only alphanumeric characters and spaces\n",
        "  article = re.sub(r'[^a-z0-9\\s]', '', article)\n",
        "  words = re.findall(r'\\b\\w+\\b', article)\n",
        "  inputs = [ids_from_chars(word) for word in words]\n",
        "  # Pad the sequences\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=seq_length, padding='pre')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  predictions = model(inputs)\n",
        "  predictions = predictions[-1, :]\n",
        "  predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "  current_body += ' '\n",
        "  current_body += ids_from_chars.get_vocabulary()[predicted_id]\n",
        "  if ids_from_chars.get_vocabulary()[predicted_id] == '\\n':\n",
        "    break\n",
        "print(current_body)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_EIHOwoQC5y",
        "outputId": "c157daea-5409-42d7-9b78-ccb3341b6c9d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New beauty product just launched in  hedge equipment on wednesday as investors bet an services group that was increased growth in new york [UNK] has cost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parece llegar a un poco más de sentido, pues parece mantener la memoria a largo plazo. Esto puede ser debido a que las celdas ahora guardan palabras en lugar de caracteres, se pierde menos la memoria. Sin embargo no se logra un buen resultado. Además, al limitar el vocabulario a las primeras 7500 palabras, es posible que aparezcan caracteres [UNK]. Esto puede ser enmendado tomando el segundo caracter más probable en el caso de que [UNK] sea el que más probabilidad tenga.\n",
        "\n",
        "A pesar de que los resultados pueden no ser los esperados, hay que tener en cuenta que queda un margen muy grande para seguir entrenando estos modelos, el problema yace en la memoria del entorno."
      ],
      "metadata": {
        "id": "8RvGrUPvQXg_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xh3q9Q13QJuk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}